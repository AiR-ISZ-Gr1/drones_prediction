{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy\n",
    "from cmdstanpy import CmdStanModel\n",
    "import cmdstanpy\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "import csv,re\n",
    "\n",
    "from DA_tools.DA_tools import ribbon_plot\n",
    "from DA_tools.FDA_data_prepare import create_spline_matrix\n",
    "from DA_tools.DA_colors import *\n",
    "import os\n",
    "plt.style.context(\"seaborn-white\")\n",
    "mpl.rcParams[\"figure.dpi\"] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIGHT = \"#B3FFFF\"  # 179, 255, 255,\n",
    "LIGHT_HIGHLIGHT = \"#9AF6FF\"  # 154, 246,255\n",
    "MID = \"#67C3FF\"  # 103,195,255\n",
    "MID_HIGHLIGHT = \"#3490CC\"  # 52,144,204\n",
    "DARK = \"#015D99\"  # 1,93,153\n",
    "DARK_HIGHLIGHT = \"#002A66\"  # 0,42,102\n",
    "GREEN = \"#00FF00\"  # RGB\n",
    "LIGHT_GREY = \"#DDDDDD\"  # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_healthy = pd.read_csv('home/data_preprocesed/acc_healthy_samples.csv')\n",
    "acc_damaged = pd.read_csv('home/data_preprocesed/acc_damaged_samples.csv')\n",
    "acc_very_damaged = pd.read_csv('home/data_preprocesed/acc_very_damaged_samples.csv')\n",
    "\n",
    "gyro_healthy = pd.read_csv('home/data_preprocesed/gyro_healthy_samples.csv')\n",
    "gyro_damaged = pd.read_csv('home/data_preprocesed/gyro_damaged_samples.csv')\n",
    "gyro_very_damaged = pd.read_csv('home/data_preprocesed/gyro_very_damaged_samples.csv')\n",
    "\n",
    "gyro_agg_healthy = pd.read_csv('home/data_preprocesed/gyro_agg_healthy_samples.csv')\n",
    "gyro_agg_damaged = pd.read_csv('home/data_preprocesed/gyro_agg_damaged_samples.csv')\n",
    "gyro_agg_very_damaged = pd.read_csv('home/data_preprocesed/gyro_agg_very_damaged_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_healthy_data = np.array([acc_healthy[col].values for col in acc_healthy.columns if col.startswith('Sample')])\n",
    "acc_damaged_data = np.array([acc_damaged[col].values for col in acc_damaged.columns if col.startswith('Sample')])\n",
    "acc_v_damaged_data = np.array([acc_very_damaged[col].values for col in acc_very_damaged.columns if col.startswith('Sample')])\n",
    "acc = [acc_healthy_data,acc_damaged_data,acc_v_damaged_data]\n",
    "\n",
    "gyro_healthy_data = np.array([gyro_healthy[col].values for col in gyro_healthy.columns if col.startswith('Sample')])\n",
    "gyro_damaged_data = np.array([gyro_damaged[col].values for col in gyro_damaged.columns if col.startswith('Sample')])\n",
    "gyro_very_damaged_data = np.array([gyro_very_damaged[col].values for col in gyro_very_damaged.columns if col.startswith('Sample')])\n",
    "gyro = [gyro_healthy_data,gyro_damaged_data,gyro_very_damaged_data]\n",
    "\n",
    "gyro_agg_healthy_data = np.array([gyro_agg_healthy[col].values for col in gyro_agg_healthy.columns if col.startswith('Sample')])\n",
    "gyro_agg_damaged_data = np.array([gyro_agg_damaged[col].values for col in gyro_agg_damaged.columns if col.startswith('Sample')])\n",
    "gyro_agg_very_damaged_data = np.array([gyro_agg_very_damaged[col].values for col in gyro_agg_very_damaged.columns if col.startswith('Sample')])\n",
    "gyro_agg = [gyro_agg_healthy_data,gyro_agg_damaged_data,gyro_agg_very_damaged_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_array,spl_order = 3, num_knots = 30, frequencies = None, mode = 'binary', training_samples = 5,lambda0=None):\n",
    "    N = len(data_array[0][0])\n",
    "    spl_order = spl_order\n",
    "    num_knots = num_knots\n",
    "    if frequencies is None:\n",
    "        times = np.linspace(0,N*10,N)\n",
    "        knot_list = np.quantile(times,np.linspace(0,1,num_knots))\n",
    "        B0 = create_spline_matrix(N, times, spl_order, num_knots)\n",
    "\n",
    "    else:\n",
    "        knot_list = np.quantile(frequencies,np.linspace(0,1,num_knots))\n",
    "        B0 = create_spline_matrix(N, frequencies, spl_order, num_knots)\n",
    "\n",
    "    K = num_knots+2\n",
    "    if mode == 'binary':\n",
    "        M = 2\n",
    "        IL1 = training_samples\n",
    "        IL2 = training_samples\n",
    "        IL = IL1+IL2\n",
    "\n",
    "        num_healthy = len(data_array[0])\n",
    "        num_damaged = len(data_array[1])+len(data_array[2])\n",
    "        data_array_damaged = np.concatenate([data_array[1],data_array[2]])\n",
    "        total = num_healthy + num_damaged\n",
    "        IT = total - IL\n",
    "\n",
    "        sampling_order_1 = np.random.permutation([*range(num_healthy)])\n",
    "        sampling_order_2 = np.random.permutation([*range(num_damaged)])\n",
    "\n",
    "        y_labeled = np.concatenate(\n",
    "        [np.array(data_array[0])[sampling_order_1[:IL1]],\n",
    "            np.array(data_array_damaged)[sampling_order_2[:IL2]]])\n",
    "        y_labeled = y_labeled.T\n",
    "        labels = np.concatenate([np.ones(IL1), 2*np.ones(IL2)]).astype(int)\n",
    "\n",
    "\n",
    "        y_test = np.concatenate(\n",
    "            [np.array(data_array[0])[sampling_order_1[IL1:]],\n",
    "                np.array(data_array_damaged)[sampling_order_2[IL2:]]\n",
    "                ]\n",
    "        )\n",
    "        y_test = y_test.T\n",
    "        y_test_labels = np.concatenate([np.ones(num_healthy-IL1), 2*np.ones(num_damaged-IL2)]).astype(int)\n",
    "        if lambda0 is None:\n",
    "            lambda0 = np.array([(IL1)/(IL), (IL2)/(IL)])\n",
    "\n",
    "        IT = y_test.shape[1]\n",
    "\n",
    "    if mode == 'all':\n",
    "        M = 3\n",
    "        IL1 = training_samples\n",
    "        IL2 = training_samples\n",
    "        IL3 = training_samples\n",
    "        IL = IL1+IL2+IL3\n",
    "\n",
    "        num_healthy = len(data_array[0])\n",
    "        num_damaged = len(data_array[1])\n",
    "        num_very_damaged = len(data_array[2])\n",
    "\n",
    "        total = num_healthy + num_damaged + num_very_damaged\n",
    "        IT = total - IL\n",
    "\n",
    "        sampling_order_1 = np.random.permutation([*range(num_healthy)])\n",
    "        sampling_order_2 = np.random.permutation([*range(num_damaged)])\n",
    "        sampling_order_3 = np.random.permutation([*range(num_very_damaged)])\n",
    "\n",
    "        y_labeled = np.concatenate(\n",
    "        [np.array(data_array[0])[sampling_order_1[:IL1]],\n",
    "            np.array(data_array[1])[sampling_order_2[:IL2]],\n",
    "            np.array(data_array[2])[sampling_order_3[:IL3]],\n",
    "            ])\n",
    "        y_labeled = y_labeled.T\n",
    "        labels = np.concatenate([np.ones(IL1), 2*np.ones(IL2), 3*np.ones(IL3)]).astype(int)\n",
    "\n",
    "\n",
    "        y_test = np.concatenate(\n",
    "            [np.array(data_array[0])[sampling_order_1[IL1:]],\n",
    "                np.array(data_array[1])[sampling_order_2[IL2:]],\n",
    "                np.array(data_array[2])[sampling_order_3[IL3:]]\n",
    "                ]\n",
    "        )\n",
    "        y_test = y_test.T\n",
    "        y_test_labels = np.concatenate([np.ones(num_healthy-IL1), 2*np.ones(num_damaged-IL2),3*np.ones(num_very_damaged-IL3)]).astype(int)\n",
    "        if lambda0 is None:\n",
    "            lambda0 = np.array([(IL1)/(IL), (IL2)/(IL), (IL3)/(IL)])\n",
    "\n",
    "        IT = y_test.shape[1]\n",
    "\n",
    "    data_out = {\n",
    "    \"N\": N,\n",
    "    \"IL\": IL,\n",
    "    \"K\": K,\n",
    "    \"M\": M,\n",
    "    \"x\": B0,\n",
    "    \"labels\": labels,\n",
    "    \"y_labeled\": y_labeled,\n",
    "    \"lambda0\": lambda0,\n",
    "    \"IT\": IT,\n",
    "    \"y_test\": y_test,\n",
    "    }\n",
    "\n",
    "    return data_out,y_test_labels,IT,IL, total\n",
    "    \n",
    "\n",
    "def get_results(model, data, seed, labels, IT, IL, total, mode = 'binary'):\n",
    "    if mode == 'binary':\n",
    "        result = model.sample(data=data, seed=seed)\n",
    "        probs_from_arviz = az.summary(\n",
    "        result, \"log_probabilities\", kind='stats', round_to=5)\n",
    "        probs_from_arviz_p = az.summary(\n",
    "            result, \"probabilities\", kind='stats', round_to=5)\n",
    "            \n",
    "        indices_cat1 = labels == 1\n",
    "        indices_cat2 = labels == 2\n",
    "\n",
    "        cat1 = probs_from_arviz.iloc[:IT, :].iloc[indices_cat1, :]\n",
    "        cat2 = probs_from_arviz.iloc[IT:2*IT, :].iloc[indices_cat2, :]\n",
    "\n",
    "        cat1p = probs_from_arviz_p.iloc[:IT, :].iloc[indices_cat1, :]\n",
    "        cat2p = probs_from_arviz_p.iloc[IT:2*IT, :].iloc[indices_cat2, :]\n",
    "\n",
    "\n",
    "        a = sum((cat1[\"mean\"].values) < np.log(0.5))\n",
    "        b = sum((cat2[\"mean\"].values) < np.log(0.5))\n",
    "\n",
    "        hit_rate = 1 - (a+b)/(total-IL)\n",
    "        print('hit rate = ',hit_rate)\n",
    "    if mode == 'all':\n",
    "        result = model.sample(data=data, seed=seed)\n",
    "        probs_from_arviz = az.summary(\n",
    "        result, \"log_probabilities\", kind='stats', round_to=5)\n",
    "        probs_from_arviz_p = az.summary(\n",
    "            result, \"probabilities\", kind='stats', round_to=5)\n",
    "            \n",
    "        indices_cat1 = labels == 1\n",
    "        indices_cat2 = labels == 2\n",
    "        indices_cat3 = labels == 2\n",
    "\n",
    "        cat1 = probs_from_arviz.iloc[:IT, :].iloc[indices_cat1, :]\n",
    "        cat2 = probs_from_arviz.iloc[IT:2*IT, :].iloc[indices_cat2, :]\n",
    "        cat3 = probs_from_arviz.iloc[2*IT:3*IT, :].iloc[indices_cat3, :]\n",
    "\n",
    "        cat1p = probs_from_arviz_p.iloc[:IT, :].iloc[indices_cat1, :]\n",
    "        cat2p = probs_from_arviz_p.iloc[IT:2*IT, :].iloc[indices_cat2, :]\n",
    "        cat3p = probs_from_arviz_p.iloc[2*IT:3*IT, :].iloc[indices_cat3, :]\n",
    "\n",
    "\n",
    "        a = sum((cat1[\"mean\"].values) < np.log(0.5))\n",
    "        b = sum((cat2[\"mean\"].values) < np.log(0.5))\n",
    "        c = sum((cat3[\"mean\"].values) < np.log(0.5))\n",
    "\n",
    "        hit_rate = 1 - (a+b+c)/(total-IL)\n",
    "        print('hit rate = ',hit_rate)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:found newer exe file, not recompiling\n",
      "INFO:cmdstanpy:CmdStan start processing\n",
      "chain 1 |\u001b[33m          \u001b[0m| 00:00 Status\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▉         \u001b[0m| 00:00 Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▊        \u001b[0m| 00:00 Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▏      \u001b[0m| 00:00 Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▌     \u001b[0m| 00:00 Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m█████▉    \u001b[0m| 00:00 Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m██████▊   \u001b[0m| 00:02 Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "chain 1 |\u001b[34m███████▋  \u001b[0m| 00:03 Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m████████▏ \u001b[0m| 00:04 Iteration: 1500 / 2000 [ 75%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m████████▋ \u001b[0m| 00:05 Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m█████████ \u001b[0m| 00:06 Iteration: 1700 / 2000 [ 85%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m█████████▌\u001b[0m| 00:07 Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m██████████\u001b[0m| 00:07 Sampling completed                       \n",
      "chain 2 |\u001b[34m██████████\u001b[0m| 00:07 Sampling completed\n",
      "\n",
      "chain 3 |\u001b[34m██████████\u001b[0m| 00:07 Sampling completed\n",
      "\n",
      "\n",
      "chain 4 |\u001b[34m██████████\u001b[0m| 00:07 Sampling completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:cmdstanpy:CmdStan done processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hit rate =  0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "frequencies = gyro_damaged['Frequencies']\n",
    "# acc, gyro, gyro_agg\n",
    "data, labels, IT, IL, total = prepare_data(acc,frequencies=None,training_samples=5,spl_order = 3, num_knots=15, mode = 'binary')\n",
    "model = CmdStanModel(stan_file='home/stan/mix.stan')\n",
    "seed = 26042024\n",
    "get_results(model=model,data=data,seed=seed,labels=labels,IT=IT,IL=IL,total=total,mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:CmdStan start processing\n",
      "chain 1 |\u001b[33m          \u001b[0m| 00:00 Status\n",
      "\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chain 1 |\u001b[33m█▎        \u001b[0m| 00:00 Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▎       \u001b[0m| 00:00 Iteration:  300 / 2000 [ 15%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m███▏      \u001b[0m| 00:00 Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m████▌     \u001b[0m| 00:00 Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m█████▉    \u001b[0m| 00:01 Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m██████▊   \u001b[0m| 00:02 Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m███████▎  \u001b[0m| 00:03 Iteration: 1300 / 2000 [ 65%]  (Sampling)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m███████▋  \u001b[0m| 00:04 Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "\n",
      "chain 1 |\u001b[34m████████▏ \u001b[0m| 00:05 Iteration: 1500 / 2000 [ 75%]  (Sampling)\n",
      "chain 1 |\u001b[34m████████▋ \u001b[0m| 00:05 Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m█████████ \u001b[0m| 00:06 Iteration: 1700 / 2000 [ 85%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m█████████▌\u001b[0m| 00:07 Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m██████████\u001b[0m| 00:08 Sampling completed                       \n",
      "chain 2 |\u001b[34m██████████\u001b[0m| 00:08 Sampling completed\n",
      "\n",
      "chain 3 |\u001b[34m██████████\u001b[0m| 00:08 Sampling completed\n",
      "\n",
      "\n",
      "chain 4 |\u001b[34m██████████\u001b[0m| 00:08 Sampling completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:cmdstanpy:CmdStan done processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hit rate =  0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "result = model.sample(data=data, seed=seed)\n",
    "probs_from_arviz = az.summary(\n",
    "result, \"log_probabilities\", kind='stats', round_to=5)\n",
    "probs_from_arviz_p = az.summary(\n",
    "    result, \"probabilities\", kind='stats', round_to=5)\n",
    "    \n",
    "indices_cat1 = labels == 1\n",
    "indices_cat2 = labels == 2\n",
    "\n",
    "cat1 = probs_from_arviz.iloc[:IT, :].iloc[indices_cat1, :]\n",
    "cat2 = probs_from_arviz.iloc[IT:2*IT, :].iloc[indices_cat2, :]\n",
    "\n",
    "cat1p = probs_from_arviz_p.iloc[:IT, :].iloc[indices_cat1, :]\n",
    "cat2p = probs_from_arviz_p.iloc[IT:2*IT, :].iloc[indices_cat2, :]\n",
    "\n",
    "\n",
    "a = sum((cat1[\"mean\"].values) < np.log(0.5))\n",
    "b = sum((cat2[\"mean\"].values) < np.log(0.5))\n",
    "\n",
    "hit_rate = 1 - (a+b)/(total-IL)\n",
    "print('hit rate = ',hit_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = result.stan_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 17]</th>\n",
       "      <td>0.99946</td>\n",
       "      <td>0.01823</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 18]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 19]</th>\n",
       "      <td>0.97324</td>\n",
       "      <td>0.12495</td>\n",
       "      <td>0.94071</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 20]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 21]</th>\n",
       "      <td>0.29970</td>\n",
       "      <td>0.39148</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.99803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 22]</th>\n",
       "      <td>0.99532</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.99990</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 23]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 24]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 25]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 26]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 27]</th>\n",
       "      <td>0.97306</td>\n",
       "      <td>0.13016</td>\n",
       "      <td>0.94969</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 28]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 29]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 30]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 31]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 32]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 33]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 34]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 35]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 36]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 37]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 38]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 39]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 40]</th>\n",
       "      <td>0.97477</td>\n",
       "      <td>0.12444</td>\n",
       "      <td>0.95670</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 41]</th>\n",
       "      <td>0.99719</td>\n",
       "      <td>0.04205</td>\n",
       "      <td>0.99990</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 42]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 43]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 44]</th>\n",
       "      <td>0.97887</td>\n",
       "      <td>0.11812</td>\n",
       "      <td>0.98180</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 45]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 46]</th>\n",
       "      <td>0.99998</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 47]</th>\n",
       "      <td>0.92546</td>\n",
       "      <td>0.21666</td>\n",
       "      <td>0.44264</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 48]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 49]</th>\n",
       "      <td>0.95361</td>\n",
       "      <td>0.17166</td>\n",
       "      <td>0.78358</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 50]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 51]</th>\n",
       "      <td>0.96819</td>\n",
       "      <td>0.13913</td>\n",
       "      <td>0.90070</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 52]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 53]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 54]</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilities[1, 55]</th>\n",
       "      <td>0.99996</td>\n",
       "      <td>0.00180</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean       sd   hdi_3%  hdi_97%\n",
       "probabilities[1, 17]  0.99946  0.01823  1.00000  1.00000\n",
       "probabilities[1, 18]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 19]  0.97324  0.12495  0.94071  1.00000\n",
       "probabilities[1, 20]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 21]  0.29970  0.39148  0.00000  0.99803\n",
       "probabilities[1, 22]  0.99532  0.05688  0.99990  1.00000\n",
       "probabilities[1, 23]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 24]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 25]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 26]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 27]  0.97306  0.13016  0.94969  1.00000\n",
       "probabilities[1, 28]  1.00000  0.00009  1.00000  1.00000\n",
       "probabilities[1, 29]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 30]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 31]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 32]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 33]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 34]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 35]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 36]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 37]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 38]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 39]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 40]  0.97477  0.12444  0.95670  1.00000\n",
       "probabilities[1, 41]  0.99719  0.04205  0.99990  1.00000\n",
       "probabilities[1, 42]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 43]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 44]  0.97887  0.11812  0.98180  1.00000\n",
       "probabilities[1, 45]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 46]  0.99998  0.00098  1.00000  1.00000\n",
       "probabilities[1, 47]  0.92546  0.21666  0.44264  1.00000\n",
       "probabilities[1, 48]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 49]  0.95361  0.17166  0.78358  1.00000\n",
       "probabilities[1, 50]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 51]  0.96819  0.13913  0.90070  1.00000\n",
       "probabilities[1, 52]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 53]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 54]  1.00000  0.00000  1.00000  1.00000\n",
       "probabilities[1, 55]  0.99996  0.00180  1.00000  1.00000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat2p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_stan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
